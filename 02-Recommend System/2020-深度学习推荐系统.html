<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>2020-深度推荐系统 - zwt的个人wiki</title>
    <meta name="keywords" content="Memory."/>
    <meta name="description" content="Wiki."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
  <div id="container" style = "width: 65em">
      
<div id="header">
  <div class="post-nav"><a href="/wiki/">Home</a>&nbsp;&#187;&nbsp;<a href="/wiki/#02-Recommend System">02-Recommend System</a>&nbsp;&#187;&nbsp;2020-深度推荐系统
    <span class="updated">Page Updated&nbsp;
      2020-06-14
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">2020-深度推荐系统</div>

  <h2 id="_1">第一章</h2>
<ul>
<li>推荐系统的意义：帮助用户在"信息过载"的情况下高效地过去兴趣信息；帮助公司做好用户增长，提高用户LTV，从而提升整体价值。</li>
<li>推荐系统的架构主要分为数据架构和模型架构。<ul>
<li>数据架构部分负责信息的收集与处理，包括离线和实时框架，该部分主要负责样本、特征和数据监控等。</li>
<li>模型架构部分是推荐系统的主体，负责推荐物料的召回与排序，并提供离线评估与在线AB测试等评估模块。</li>
</ul>
</li>
</ul>
<h2 id="-">第二章 - 深度学习之前的推荐系统</h2>
<ul>
<li>协同过滤（Collaborative Filtering）<ul>
<li>将"共现矩阵中的向量"通过"相似度计算方法"计算得到相似度，并利用相似度加权将评分求和得到目标值。</li>
<li>基于用户的cf/基于item的cf，分别对应基于用户相似度/基于物品的相似度进行推荐。</li>
</ul>
</li>
<li>矩阵分解（Matrix Factorization）<ul>
<li>定义用户向量矩阵与item向量矩阵，两者矩阵乘积为共现矩阵。</li>
<li>利用交替最小二乘（ALS）方法求解，并可以设置正则项。</li>
</ul>
</li>
<li>逻辑回归（Logistic Regression)<ul>
<li>本质上是利用线性回归学习几率。</li>
<li>优点是结构简单，可解释性强；缺点是表达能力不强。</li>
</ul>
</li>
<li>FM与FFM<ul>
<li>FM能够学习特征的交叉信息，详见FM论文笔记。</li>
<li>FFM引入了Filed的概念，特征被划分为多个Filed，每个特征对与不同的Field设置不同的隐向量。</li>
</ul>
</li>
<li>GBDT+LR<ul>
<li>本质上是利用GBDT来做特征工程，再用LR模型做训练。</li>
<li>GBDT输出的是样本落入各决策树叶子节点的编号向量。</li>
</ul>
</li>
<li>混合逻辑回滚（MLR）<ul>
<li>本质上对于不同的数据利用不同LR函数来拟合。</li>
<li>例如利用softmax函数来对所有的LR函数输出做加权求和，有点像attention机制。</li>
</ul>
</li>
</ul>
<h2 id="-_1">第三章 - 深度学习在推荐系统中的应用</h2>
<ul>
<li>自编码器（AutoRec）<ul>
<li>三层神经网络，输入层是评分向量，训练使得输出层和输入层的误差最小（只考虑输入层有值的误差），输出层即是预测的评分向量。</li>
</ul>
</li>
<li>Deep Cross模型<ul>
<li>特征embedding后拼接并进入mlp，相比之前的突破点是特征embedding。</li>
</ul>
</li>
<li>NeuralCF<ul>
<li>矩阵分解其实就是使得user向量和item向量内积为评分值，NeuralCF将内积操作改成mlp。</li>
<li>这里能联想到DSSM的结构，矩阵分解是直接内积，DSSM是先将两个向量经过mlp再内积。</li>
<li>NeuralCF和矩阵分解是直接对id进行embedding，而DSSM考虑了其他的特征。</li>
</ul>
</li>
<li>PNN（product）<ul>
<li>特征embedding后进行交叉内积并进入mlp，相当于是在FM上加mlp。</li>
<li>乘积层包括内积和外积操作，为了减小模型负担，该模型提出将所有特征的外积矩阵求和，这个操作会模糊掉特征中的信息，一般不建议使用。</li>
</ul>
</li>
<li>Wide&amp;deep<ul>
<li>主要目的是同时利用先验信息和潜在信息，详见Wide&amp;deep论文笔记。</li>
<li>之后的很多论文都是在此基础上改进wide/deep部分的结构。</li>
</ul>
</li>
<li>DCN（deep&amp;cross)<ul>
<li>利用cross结构代替wide部分，cross结构利用向量外积将特征充分交叉，并在每一层都保留了输入向量，模型的非线性学习能力更强。</li>
<li>我理解这边可以将特征外积与输入向量分开，这样可以更针对性的学习特征交叉信息。</li>
</ul>
</li>
<li>FM和深度学习的结合<ul>
<li>FNN，为了加速embedding部分的收敛速度，利用FM做预训练，将FM各特征的隐向量来初始化dnn的特征embedding参数。</li>
<li>DeepFM，将FM结构代替wide部分，同时具备了特征低阶交叉和高阶交叉，并利用embedding解决了稀疏特征的参数规模较大问题。</li>
<li>NFM，FM二阶交叉部分用的是内积，在NFM中用了向量元素乘法保留了整个向量，并将所有交叉向量求和输出到mlp中。</li>
</ul>
</li>
<li>attention在推荐模型中的应用<ul>
<li>AFM，在特征交叉层之后加入attention结构，对下一层的输出进行加权求和，是模型结构上的一次尝试。</li>
<li>DIN，针对业务特点在用户历史行为中加入attention结构，详见DIN笔记。</li>
<li>DIEN，引入用户历史行为的"序列信息"，详见DIEN笔记。</li>
</ul>
</li>
<li>强化学习和推荐系统的结合<ul>
<li></li>
</ul>
</li>
</ul>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2020 zwt.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2020-06-27 11:49:55</p>
      </span>
    </div>

    
    
  </body>
</html>