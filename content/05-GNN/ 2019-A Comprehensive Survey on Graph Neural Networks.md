---
title: "2019-A Comprehensive Survey on Graph Neural Networks"
layout: page
date: 2020-07-04
---

## 总结

- 介绍了GNN的主要研究方向，详见对应的GNN笔记。
 
## 主要内容

- 常规的训练数据都是欧式空间数据（线性，可以用数据直接表示），但现实中很多数据之间的关系是复杂的，因此图结构就被用来表示数据之间的复杂关系和依赖结构。图机构的复杂性给常规的机器学习算法打来了挑战，所以出现了很多处理图结构的深度学习方法。
- GNN和GE的关系
    - GE的目的是将图数据信息进行embedding，包括矩阵分解、随机游走和图深度网络（例如图自编码网络）。
    - GNN主要分为GCN,GAN,GAE,GGN,GSTN五种类型。
    
- GCN，图卷积网络
    - GCN将传统数据的卷积算子泛化到图数据。
    - 频域卷积
    - 空间域卷积
        - 基于循环的空间GCN，主要思想是递归地更新节点的潜在表示，直到达到稳定的不动点，目的是获得节点的稳定状态。
        - 基于组合的GCN，基于组合的方法通过叠加多个图的卷积层来更新节点的表示，目的是合并更高阶的领域信息。
    - 图的pooling
    - 频域和空间域GCN对比
        - 基于频域GCN方法为图信号处理奠定了一个理论基础，但在效率、通用型和灵活性三个方面不如空间域GCN。
        - 效率：在庞大的图结构数据中，空间域GCN是对领域进行计算，而频域GCN需要对整个图进行计算，计算量随图数据大小急剧增加。
        - 通用性：频域GCN假设图结构是固定的，对不同的图数据泛化能力差；空间域GCN邻域卷积的权值可以共享。
        - 灵活性：频域GCN只适用于无向图，如果要用于有向图则需要转换；空间域GCN则可以通过定义不同的聚合函数来处理。
        
- GAN，图注意力网络
    - 在聚合邻域信息时不同邻居节点有不同的权值，常用于基于空间的GCN中。
    - 根据注意力权重集成多个模型。
    - 使用注意力权重指导随机游走。
    
- GAE，图自编码网络
    - 目的是图数据的embedding，是GE的一种类型，主要思想与常规的自编码网络类似。
    
- GGN，图生成网络
    - 目的是在给定一组已知图的前提下生成新的图，使用了MolGAN的框架。
    
- GSTN，图时空网络
    - 目的是同时捕获时空图数据中时间与空间的依赖性。